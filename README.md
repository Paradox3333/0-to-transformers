# Transformers-from-Scratch
Building Generative Pre-trained Transformers from the Ground Up.

This series is designed for educational purposes, providing both code and detailed explanations, all contained in easy-to-run Jupyter notebook files.

Series order:

1. bigram_models.ipynb
2. MLP_char_pred.ipynb
3. batch_norm_and_diagnostics.ipynb
4. backpropagation.ipynb
5. wave_net_and_cnns.ipynb
6. simple_gpt.ipynb

## Acknowledgements
This reimplementation is inspired by the original work of [Andrej Karpathy](https://github.com/karpathy), specifically his project [makemore](https://github.com/karpathy/makemore).

A sincere thank you to Andrej for his contributions.
